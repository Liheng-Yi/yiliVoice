zero_shot_prompting: Country,val:{'Precision': 0.830428165547988, 'Recall': 0.8099518488435185, 'F1': 0.8196208003689262} 
zero_shot_prompting: State,val:{'Precision': 0.23529413167168112, 'Recall': 0.23529413167168112, 'F1': 0.23529413167168112} 
zero_shot_prompting: City,val:{'Precision': 0.27883875720641194, 'Recall': 0.2815951073870939, 'F1': 0.2801603446988499} 
zero_shot_prompting: Continent,val:{'Precision': 0.8459482263116276, 'Recall': 0.7946009250248179, 'F1': 0.817373489632326} 
zero_shot_prompting: Company,val:{'Precision': 0.5332607732099646, 'Recall': 0.5235504946287941, 'F1': 0.5273831504232743} 
zero_shot_prompting: Company city,val:{'Precision': 0.5998858160832349, 'Recall': 0.605241489761016, 'F1': 0.601650628973456} 
zero_shot_prompting: Company state,val:{'Precision': 0.7106982154004714, 'Recall': 0.7067493130179012, 'F1': 0.7086054682731628} 
zero_shot_prompting: Affected population,val:{'Precision': 0.5289342087857863, 'Recall': 0.5205970353939954, 'F1': 0.5230993435663336} 
zero_shot_prompting: Number of people actually affected,val:{'Precision': 0.9285177623524385, 'Recall': 0.9107725199531106, 'F1': 0.9180095195770264} 
zero_shot_prompting: Number of people potentially affected,val:{'Precision': 0.871358640053693, 'Recall': 0.886824327356675, 'F1': 0.87786086341914} 
zero_shot_prompting: Classes of irresponsible AI use,val:{'Precision': 0.7387598104336682, 'Recall': 0.8472875006058637, 'F1': 0.7806487854789285} 
zero_shot_prompting: Subclasses,val:{'Precision': 0.564173500327503, 'Recall': 0.5668491861399483, 'F1': 0.5585586726665497} 
zero_shot_prompting: Sub-subclass,val:{'Precision': 0.17184073083540974, 'Recall': 0.18671180570826812, 'F1': 0.17787153931225047} 
zero_shot_prompting: Area of AI Application,val:{'Precision': 0.5773742093759424, 'Recall': 0.637593183447333, 'F1': 0.6041633609463187} 
zero_shot_prompting: Online,val:{'Precision': 0.972157499369453, 'Recall': 0.972157499369453, 'F1': 0.9721574923571419} 
few_shot_CoT_prompting: Country,val:{'Precision': 0.830428165547988, 'Recall': 0.8099518488435185, 'F1': 0.8196208003689262} 
few_shot_CoT_prompting: State,val:{'Precision': 0.23529413167168112, 'Recall': 0.23529413167168112, 'F1': 0.23529413167168112} 
few_shot_CoT_prompting: City,val:{'Precision': 0.27883875720641194, 'Recall': 0.2815951073870939, 'F1': 0.2801603446988499} 
few_shot_CoT_prompting: Continent,val:{'Precision': 0.8459482263116276, 'Recall': 0.7946009250248179, 'F1': 0.817373489632326} 
few_shot_CoT_prompting: Company,val:{'Precision': 0.5488037326756645, 'Recall': 0.5240254507345312, 'F1': 0.5355401985785541} 
few_shot_CoT_prompting: Company city,val:{'Precision': 0.5902649690123165, 'Recall': 0.5894085782415727, 'F1': 0.5885151291594786} 
few_shot_CoT_prompting: Company state,val:{'Precision': 0.6995587804738213, 'Recall': 0.6956098780912512, 'F1': 0.6974660298403572} 
few_shot_CoT_prompting: Affected population,val:{'Precision': 0.5343303908320034, 'Recall': 0.5138745062491473, 'F1': 0.5212401362026439} 
few_shot_CoT_prompting: Number of people actually affected,val:{'Precision': 0.9285177623524385, 'Recall': 0.9107725199531106, 'F1': 0.9180095195770264} 
few_shot_CoT_prompting: Number of people potentially affected,val:{'Precision': 0.8631098621031817, 'Recall': 0.874327540397644, 'F1': 0.8677107796949499} 
few_shot_CoT_prompting: Classes of irresponsible AI use,val:{'Precision': 0.7556737749015584, 'Recall': 0.8819247869884267, 'F1': 0.8086093664169312} 
few_shot_CoT_prompting: Subclasses,val:{'Precision': 0.6417273528435651, 'Recall': 0.6419333745451534, 'F1': 0.6395496305297402} 
few_shot_CoT_prompting: Sub-subclass,val:{'Precision': 0.16545563410310185, 'Recall': 0.18025076739928303, 'F1': 0.17145109702559078} 
few_shot_CoT_prompting: Area of AI Application,val:{'Precision': 0.6049353830954608, 'Recall': 0.6391378325574538, 'F1': 0.6197959657977609} 
few_shot_CoT_prompting: Online,val:{'Precision': 0.9582362490541795, 'Recall': 0.9582362490541795, 'F1': 0.9582362385357127} 
tot_few_shot_prompting: Country,val:{'Precision': 0.8582806797588572, 'Recall': 0.8411999414948856, 'F1': 0.8492695724262911} 
tot_few_shot_prompting: State,val:{'Precision': 0.23529413167168112, 'Recall': 0.23529413167168112, 'F1': 0.23529413167168112} 
tot_few_shot_prompting: City,val:{'Precision': 0.27883875720641194, 'Recall': 0.2815951073870939, 'F1': 0.2801603446988499} 
tot_few_shot_prompting: Continent,val:{'Precision': 0.8705176290343789, 'Recall': 0.8255778901717242, 'F1': 0.8454772409270791} 
tot_few_shot_prompting: Company,val:{'Precision': 0.5434806522201089, 'Recall': 0.5280170826350942, 'F1': 0.5347318368799546} 
tot_few_shot_prompting: Company city,val:{'Precision': 0.5998858160832349, 'Recall': 0.605241489761016, 'F1': 0.601650628973456} 
tot_few_shot_prompting: Company state,val:{'Precision': 0.7106982154004714, 'Recall': 0.7067493130179012, 'F1': 0.7086054682731628} 
tot_few_shot_prompting: Affected population,val:{'Precision': 0.5258005664629095, 'Recall': 0.49612395027104544, 'F1': 0.5070707131834591} 
tot_few_shot_prompting: Number of people actually affected,val:{'Precision': 0.9191616615828346, 'Recall': 0.9129083612385918, 'F1': 0.9146723466760972} 
tot_few_shot_prompting: Number of people potentially affected,val:{'Precision': 0.9910759154488059, 'Recall': 0.9910759154488059, 'F1': 0.9910759154488059} 
tot_few_shot_prompting: Classes of irresponsible AI use,val:{'Precision': 0.7575635296456954, 'Recall': 0.8648186501334695, 'F1': 0.7991939712973202} 
tot_few_shot_prompting: Subclasses,val:{'Precision': 0.6334974520346698, 'Recall': 0.6151878588339862, 'F1': 0.6200965993544635} 
tot_few_shot_prompting: Sub-subclass,val:{'Precision': 0.17519607263452866, 'Recall': 0.18793749458649578, 'F1': 0.1803162693977356} 
tot_few_shot_prompting: Area of AI Application,val:{'Precision': 0.631761792828055, 'Recall': 0.6782790913301355, 'F1': 0.6504081505186418} 
tot_few_shot_prompting: Online,val:{'Precision': 0.9721575133940753, 'Recall': 0.9721575133940753, 'F1': 0.9721575063817641} 